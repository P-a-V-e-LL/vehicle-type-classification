

# Vehicle Type Classification

Здесь находятся программы, предназначенные для сборки датасета, обучения нейронной сети и оценки ее качества.

# Installation
1.Клонировать репозиторий:
```
git clone git@gitlab.inventos.ru:neurowebs/vehicle-type-classification.git
```
2.Создать новое вируальное окружение:
```
python3.7 -m venv new_venv
source new_venv/bin/activate
```
3.Установить зависимости:
```
pip install -r requirements.txt
```
4.Перейти в папку car_detect. Использовать скрипт use_to_install.sh

# freeze.py

Замораживает или размораживает все слои модели, кроме последнего.

Аргументы:
- --model_path - путь до модели. Обязательный.
- --action - установить True если нужно разморохить слои, иначе игнорировать. По умолчанию False.

# tf_jetson_test.py

 Определяет количество кадров в секунду и время обработки одного кадра моделью tflite.

Аргументы:
- --model_path - путь к tflite модели. По умолчанию "./models/facenet_l2_bn.tflite".
- --data_path - путь к изображению для распознавания. Обязательный.

# car_nn.py

Программа вырезает кабины автомобилей из видео.
Каждую вырезанную кабину называет в соответствии с номером автомобиля.
Использует нейросеть распознавания номеров, распознавания классов автомобилей.
Используем для формирования первоначального (неразмеченного) датасета.

Для работы подгатавливаются папка с видео, на которых необходимо распознать автомобили, папка для сохранения изображений распознанных автомобилей.
Также необходимо указать пути для файлов: нейронная сеть для распознавания номеров, нейронная сеть для распознавания автомобилей, текстовый файл с описанием классов авто.
Три последних файла можно найти в папке car_detect.

Обязательные аргументы:
- --video_path - путь к папке с видео для распознавания.

# classifier_demo.py

Программа для демонстрации работы с классом `Classifier`, который отвечает за окончательную классификацию транспортного средаства.

Аргументы:
- --model_path - путь к модели h5 или tflite. Обязательный.
- --test_image_path - путь к распознаваемому изображению. По умолчанию "./data/dataset3.11_new_split/val/LADA VAZ Kalina/car_903.jpg".
- --pickle_file_path - путь к pickle файлу с векторами данных. Обязательный.

# yolox_demo.py

Программа для демонстрации работы с классом `InferenceYoloxOnnx`, который отвечает за выполнение
YOLOX с помощью onnxruntime. Есть возможность сохранить визуализированные прямоугольники для входного изображения.

Аргументы:
* --model: Путь до модели в формате onnx. Обязательный.
* --image_path: Путь до тестируемого изображения. Обязательный.
* --save_image: Сохранять ли изображение с найденными прямоугольниками. По умолчанию: `True`

Пример запуска:
```python
python3 yolox_demo.py --model car_detect/five_car_class_yolox_s_190122.onnx --image_path yolox/bus.jpg
```

# model_training.py

Программа выполняет обучение нейронной сети с помощью tensorflow. Результатом работы программы является модель формата .h5, обученная на подготовленных наборах данных.

Для работы программы необходимо подготовить два набора данных - обучающий и валидационный. Каждый набор должен быть разделен по классам и иметь вид:

```
root_dir:
	Class_1:
		img1
		img2
		img3
		...
	Class_2:
		img1
		img2
		img3
		...
	Class N:
		...
```

Все изображения должны быть в чёрно-белом формате (для этого можно использовать программу to_gray.py).
root_dir является папкой, в которой хранится весь набор данных. Именно она указывается как путь к набору данных.
Также необходимо указать путь для сохранения обученной модели.
Во время обучения программа сохраняет значения ошибки и точности в папку logs. По этим данным можно построить графики с помощью tensorboard.

Далее необходимо указать путь до модели нейронной сети, котрая будет обучаться в процессе работы программы. Модель должна быть в формате .h5.
И под конец необходимо указать такие параметры, как размер батча, ширину и высоту изображения для предобработки, количество эпох обучения, а текже колчичество одучающих и валидационных изображений (для этого можно воспользоваться программной check.py).

Аргументы:
- --model_path - путь до .h5 keras модели. Обязательный.
- --train_data - путь до папки с обучающей выборкой данных. Обязательный.
- --val_data - путь до папки с валидационной выборкой данных. Обязательный.
- --epochs - количество эпох обучения. Обязательный.
- --batch_size - размер батча. По умолчанию 128.

# ds_train_val_test_cut.py

Проводит разбиение одного целого набора данных на обучающий и валидационный в заданном соотношении.

Для работы программы необходимо указать путь до root_dir исходного набора данных (для разделения), а также папки для сохранения обучающей и валидационной выборок. Исходный набор данных не будет изменен в процессе работы программы.

Аргументы:
- --data_dir - путь до общего набора данных. Обязательный.
- --train_dir - путь для сохранения обучающей выборки данных. Обязательный.
- --val_dir - путь до сохранения валидационной выборки данных.Обязательный.


# GRZ_get.py

Программа позволяет, используя государственный номер транспортного средства, узнать марку, модель и год транспортного средства. Программа обращается за данными к SpectrumData API.

Для работы программы необходима версия python 3.9 и выше. Данную версию нужно установить отдельно - только этой программе требуется высокая версия python.
Перед запуском программы необходимо получить токен авторизации на SpectrumData и указать его в программе. Помимо этого, на вход программа принимает путь до папки с изображениями, в названии которых находится лишь номер транспортного средства (прим. 'E020BX154.jpg').

В процессе работы программы каждое изображение получает новое название в соответствии со своими маркой и моделью, либо удаляется (в случае отсутствия номера в базе данных). Каждый новый номер записывается в файл data.txt, таким образом, если какой-то номер уже когда-то был распознан, то название будет просто извлечено из файла без обращения к SpectrumData.

# to_gray.py

Преобразует изображения для обучающей и валидационной выборок в чёрно-белый формат.

Для работы программы необходимо указать папку, в которой находятся необходимые наборы данных. Папки с наборами данных должны называться train и val соответственно, и располагаться внутри указанной ранее папки.

Аргументы:
- --root_dir - путь до набора данных. Обязательный.

# affin.py

Преобразует изображения используя случайное сочитание эффектов (поворот, отзеркаливание, шум, контраст, дождб, снег, туман, размытие при движении, зум и обрезание небольшой части изображения).

Для работы программы необходимо указать root_dir для набора данных. В результате работы программы в папке каждого класса появится n новых изображений с эффектами. Каждое ново изображение основано на уже существующем внутри класса изображении. Также можно внутри программы указать общее желаемое число изображений в каждом классе (по умолчанию 210).

Все новые изображения сохраняются в папку класса, в котором лежали их оригиналы.

Аргументы:
- --root_dir - путь к выборке данных. Обязательный.

# vizualize_cluster.py

Визуализирует кластеризацию модели. Для работы программы нужна модель .h5 и набор размеченных данных, пути до которых указываются внутри программы.

Аргументы:
- --model_path - путь до .h5 keras модели. Обязательный.
- --root_dir - путь до папки с выборкой данных. Обязательный.
- --filename - название файла, в котором будут сохранены данные. Обязательный.

# data_to_embedding.py

Сохраняет эмбединги выборки данных в файл с расширением .pickle. Для работы программы нужны обученная модель .h5 и выборка данных для сохранения.

После работы программы файл с данными будет сохранен в папке embedding_data.

Аргументы:
- --model_path - путь до .h5 keras модели. Обязательный.
- --root_dir - путь до папки с выборкой данных. Обязательный.
- --data - название файла для сохранения данных. Обязательный.


 Аргументы на выбор (обязательно должен быть один из двух):
- --all - сохраняет все доступыне изображения. По умолчанию False.
- --n - количество изображений для сохранения из каждого класса. По умолчанию 1.


# get_knn.py

Вычисляет принадлежность тестового изображения к классам, записанным в .pickle файл. Для работы программы нужна обученная модель, тестовое изображение и файл с эмбеддингами и их классами.

Аргументы:
- --model_path - путь до .h5 keras модели. Обязательный.
- --test_image_path -  путь до изображение, которое нужно классифицировать. Обязательный.
- --pickle_file_path - путь до .pickle файла с данными. Обязательынй.
- --min_dist - минимильное расстояние между классами. По умолчанию 0.6.
- --knn_count - количество ближейших соседей, которое нужно вывести. По умолчанию 10.

# pickle_to_tensorboard.py

Переводит данные из .pickle файла в формат для визуализации в [embedding projector](https://projector.tensorflow.org/). На выходе программы получаются дв файла: вектора и метаданные.

Аргументы:
- --pickle_path - путь до .pickle файла с индексом эмбеддингов. Обязательный.

# data_to_csv.py

Записывает информацию о датасете в csv файл.
Структура записи: [название изображения, название класса, высота, ширина, выборка, путь до изображения]

Аргументы:
- --filename - название файла для сохранения (будет расположен в папке ./data/). Обязательный.
- --data_path - путь к набору данных (местоположение выборок данных). Обязательный.
- --train_data - флаг наличия обучающей выборки в директории data_path. По умолчанию False.
- --val_data - флаг наличия валидационной выборки в директории data_path. По умолчанию False.
- --test_data - флаг наличия тестовой выборки в директории data_path. По умолчанию False.

# change_emb_layer.py

Меняет размер выходного вектора модели facenet.

Аргументы:
- --model_name - название для новой модели. Новая модель будет сохранена в папке ./models/. Обязательный.
- --dim - размер для выходного вектора. Обязательынй.
- --l2 - добавляет l2 нормализацию в конец модели если True, по умолчанию False.

# Наборы данных

- cars196 - размеченный набор данных из открытого доступа.
- dataset3.11 - вручную собранный, размеченный набор данных.

Наборы данных можно молучить с помощью скрипта from_minio.sh. Необходимо запустить скрипт с единственным аргументом - названием датасета (указаны выше).
```
bash from_minio.sh dataset3.11
```
# Модели

- facenet_keras - оригинальный Facenet с выходным вектором 128 D.
- facenet512 - оригинальный Facenet с выходным вектором 512 D.
- facenet_l2_bn - facenet с добавленным выходным слоем l2 нормализации, обученый на dataset3.11_new_split (сначала учился только l2 слой, затем модель целиком).
- 2.5facenet_l2_bn - то же что и facenet_l2_bn, но при создании и обучении использовался tensorflow версии 2.5.

Модели можно получить с помощью скрипта get_model_from_minio.sh. Необходимо запустить скрипт с единственным аргументом - названием модели (указаны выше). Выбранная модель будет загружена в папку models.

```
bash get_model_from_minio.sh facenet_keras
```
